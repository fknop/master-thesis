% !TEX root = ../../thesis.tex

\documentclass[../../thesis.tex]{subfiles}
 
\begin{document}


\section{Constraint Programming model}
\label{section:cpmodel}

We now present our Constraint Programming model. This model contains some differences
with the mathematical model described in \autoref{section:mipmodel}.
For example, a Constraint Programming model rarely contains binary variables to refer to multiple values 
of a domain. Instead, it uses integer variables having the entire domain. 
Typically, binary variables $w_0, \dots, w_i, \dots, w_n$ where $i \in W$ and $w = i$ if $w_i = 1$ are equivalent to 
one variable $w \in \{0, \dots, n\}$.



\subsection{Variables}

First, we need to express the set of workers for each demand at each time period at which that demand occurs.

\begin{equation}
\begin{split}
    w_{ijk} \in W \label{cpworkervariable} \\
\end{split}
\end{equation}

(\ref{cpworkervariable}) is the worker working at time $i$ for demand $j$ at the $k$th position 
with $t_i \in T$, $d_i \in D$, $t_i \in d_j^T$ and $k \in d^P_j$. The same reasoning is used for locations and machines:

\begin{align}
    m_{ij} &\in M \label{cpmachinevariable} \\ 
    l_i &\in L \label{cpzonevariable} 
\end{align}

(\ref{cpmachinevariable}) is the $j$th machine used for demand $i$ while (\ref{cpzonevariable}) is the location used for demand $i$.



As explained in the problem description and in the mathematical model section,
we need to allow partial solutions in which we have a dummy worker that can work at any time.
We add this value to every worker variable domain but ignore it during the constraint propagation. We define 
this worker by $\sigma \notin W$. The actual value of this worker does not matter as long as it does not belong to $W$. For simplicity, we define $\sigma = -1$.


The variables modeling already satisfies some constraints, like the number of required resources (i.e. worker, location, machine)
per demand. We also satisfy the required skills and availabilities for each position by only initializing variables with the 
possible workers. Let $W_{d^{s_k}_j} \subseteq W$ be the subset of workers that satisfy the $k$th skill (set of skills) of demand $d_j$.

\begin{equation}
  \label{wdomain}
  w_{ijk} \in W_{d^{s_k}_j} \cap \{ w \mid t_i \in w^T \} \cup \{ \sigma \}, \forall j \in D, i \in d^T_j, k \in d^P_j
\end{equation}

Note that initializing the variables with a reduced set of values is semantically equivalent to adding a \texttt{not\_equal} constraint for each impossible value.


We also follow the same principle for the locations and machines by reducing the domain at initialization instead of adding constraints.
For each required machine in a demand, we take all possible machines of this type in $M$.

\begin{equation}
  \label{mdomain}
  m_{ij} \in \{ m \mid m \in M, m = d_i^{M_j}  \}, \forall i \in D, j \in |d_i^M|
\end{equation}

For each location of a demand, the domain is the possible locations of that demand.

\begin{equation}
  \label{ldomain}
  l_i \in d_i^L, \forall i \in D
\end{equation}


\subsection{Constraints}

\subsubsection{All workers for one period must be different}

All the worker variables for a given time period must be different. 
The \texttt{alldifferent} (\autoref{sota:alldifferent}) constraint is well suited to express this. 
However, as our model has the dummy worker $\sigma$ in the domain of all worker variables and this value 
can appear as many times as possible, we need a slight variant of the \texttt{alldifferent} called \texttt{alldifferent\_except}. 
This constraint has the same behavior as the original except that we can specify values that are ignored from 
the constraint propagation.

\begin{align*}
   \texttt{alldifferent\_except} (X, v) = \{& (d_1, \dots, d_n) \mid d_i \in D(x_i), \\ 
   & d_i \notin v \ \land \ d_j \ \notin v \implies d_i \neq d_j \ \forall i \neq j \}
\end{align*}

We use this constraint to ignore the $\sigma$ value from the propagation. Let $X_i = \{w_{ijk} \mid j \in D, k \in d_j^P \}$ be the set of all worker variables for period $i$. For each period, we define:

\begin{equation}
  \texttt{alldifferent\_except}(X_i, \{ \sigma \}), \forall i \in T
\end{equation}

\subsubsection{Incompatibilities between workers and clients}

A worker might have an incompatibility with a client or a set of clients. 
Clients are statically assigned to demands, we can solve this constraint by adding 
a series of \texttt{not\_equal} constraints for each incompatible worker-client pair.

\begin{equation}
  \texttt{not\_equal}(w_{ijk}, w), \forall (w, c) \in I_{wc}, i \in T, j \in \{ d \mid d \in D \land d^c = c \}, k \in d_j^P
\end{equation}

\subsubsection{Incompatibilities between workers}

A worker might have an incompatibility with another worker or a set of workers. 
Unlike the worker-client incompatibilities, we cannot solve this constraint with a series of \texttt{not\_equal} constraints. We instead use a constraint 
called \texttt{negative\_table}. This constraint is a type of \emph{Table Constraints} \cite{Henteryck:Table} which in general can
express either the allowed or forbidden combinations of values. In this case, \texttt{negative\_table} expresses the forbidden combinations of values.
These combinations are expressed by the table $I_{ww}$. 
We add a \texttt{negative\_table} constraint for each pair of workers for a demand at one given time. Let $P_{ij} = \{ (w_{ijk}, w_{ijl}) \mid k \in d_j^P, l \in d_j^P, k \neq l \}$ 
be the permutations of worker variables for demand $j$ at period $i$:

\begin{equation}
  \texttt{negative\_table}(x, y, I_{ww}),  \forall (x, y) \in P_{ij}
\end{equation}

In practice, we can slightly reduce the number of constraints by checking first if each pair of workers are indeed working for these positions.

\subsubsection{Additional skills must be satisfied}

A demand can have what we call additional skills. Those skills can be 
satisfied by any workers in the demand. Unlike required skills by different workers,
we cannot pre-assign possible values to the domains of variables. Any number of workers in the demand can have an additional skill.
We use the \texttt{gcc} constraint coupled with a \texttt{sum} constraint.
The \texttt{gcc} acts as a counter of occurrences for the workers that satisfy the skills,
the sum states that at least one worker needs to be assigned.

Let us define $o_{ijs}$ the occurrences of workers at time $i$ for demand $j$ in $W_s$ (the set of workers that satisfy skill $s$).

\begin{align}
  &\texttt{gcc}(\{ w_{ijk} \mid k \in d^P_j \}, o_{ijs}) \\ 
  &\texttt{sum}(o_{ijs}) \geq 1 \\
  \text{with} \quad & o_{ijs} \in \{ 0, 1 \} \\
  & \forall j \in D, s \in d^{S^{+}}, i \in d^T_j
\end{align}

This is a different syntax for \texttt{gcc} from what we introduced before. This variant takes 
variables and assigns the occurrences of values to them. In this case, the \texttt{gcc} assigns 
occurrences of $w \in W_s$ to $o_{ijs}$ and the \texttt{sum} constraint ensures that 
these occurrences sum to at least one.


\subsubsection{Machines can only be assigned once per period}

As machines can only be assigned once per period and are assigned for the entirety of a demand. We need 
to ensure that a machine is not assigned to two overlapping demands in time.
For each pair of overlapping demands,
we add a \texttt{alldifferent} constraint with all the machine variables associated to the two demands.

\begin{equation}
  \label{}
  \texttt{alldifferent}(\{ m_{ij} \mid j \in |d_i^M| \} \cup \{ m_{kj} \mid j \in |d_k^M| \}), \forall i \in D, k \in d^O_i
\end{equation}

\subsubsection{Locations can only be assigned once per period}

As with machines, locations can only be assigned once per period and are assigned for the entirety of a demand. We need 
to ensure that a location is not assigned to two overlapping demands in time. For each pair of overlapping demands,
we add a \texttt{not_equal} constraint with the two associated location variables.

\begin{equation}
  \label{}
  \texttt{not_equal}(l_{i}, l_{k}), \forall i \in D, k \in d^O_i
\end{equation}


\subsubsection{Minimizing violations of working requirements}

Workers might have working requirements. They have to work for a minimum (maximum) number of times, hence the total 
occurrences of these workers must be above (below) or equal the requirements. As a solution cannot always be 
achieved with these requirements, we use a soft constraint and minimize the number of violations. In this case,
we use the \texttt{softgcc} constraint introduced in \autoref{sota:gcc}. Let $X$ be the entire set of variables and 
$v_r$ the total number of violations.

\begin{equation}
  \texttt{softgcc}(X, [r_{1_{min}}, \dots, r_{n_{min}}], [r_{1_{max}}, \dots, r_{n_{max}}], v_{r}) \label{cp:wrequirements} 
\end{equation}

Note that from a model point of view, if a worker does not have any requirement, $r_{min}$ is 0 and $r_{max}$ is $|{r_w}^T| $ (i.e. the number of availabilities of that worker).


\subsubsection{Minimizing the number of dummy workers}

A solution might not always be possible, leading to a partial solution containing dummy workers.
We defined this dummy worker by the value $\sigma$. This is again a case of soft constraint where 
we use a \texttt{softgcc}. Let $v_{\sigma}$ be the total number of violations.


\begin{equation}
  \texttt{softgcc}(X, \sigma \rightarrow \sigma, [0], [0], v_{\sigma}) \label{cp:dummy}
\end{equation}

This syntax is a little bit different than what was introduced before. We specify $\sigma \rightarrow \sigma$ to check only the occurrences of values 
in that range, hence only $\sigma$ in our case.




\subsubsection{Objective Function}

We already defined violations $v_r$ (\ref{cp:wrequirements}) and $v_{\sigma}$ (\ref{cp:dummy}) as our working requirements and dummy worker violations respectively.
We also need to define a final part of our objective function which is not a violation per se. Let $N_{jk}$ be the number 
of different workers working for demand $j$ at position $k$ throughout the periods $d_j^T$. We use a 
constraint called \texttt{at\_least\_nvalue} \cite{nvalue} to count this number.
Let  $W_{jk} = \{ w_{ijk} \mid i \in d^T_j \}$ be the set of worker variables for demand $j$ at position $k$ across all time periods for that demand:

\begin{equation}
  \texttt{at\_least\_nvalue}(W_{jk}, N_{jk}) \ \forall j \in D, k \in d^P_j
\end{equation}

We now have the number of different workers for each shift and we need to minimize the sum of all $N_{jk}$ to avoid perturbations (change of worker).

The final objective is a weighted-sum of all sub-objectives in the model. However, not all objectives are equal 
in values, some objectives need bigger penalties when violated. This is the case for $v_r$ and $v_{\sigma}$.
We define three penalties $\delta_0$, $\delta_1$ and $\delta_2$ which are associated with our three sub-objectives.

\begin{equation}
  \text{min} \quad \delta_0 \big( \sum_{j \in D} \sum_{k \in D^P_j} N_{jk} \big) + \delta_1 v_r + \delta_2 v_{\sigma} \label{cp:objective}
\end{equation}

\begin{equation}
  \label{penalties:cp}
  \bm{\delta} = (\delta_0, \delta_1, \delta_2)
\end{equation}




\subsection{Search}

We now define the variable and value heuristics used in our model. The variable heuristic is a variant of the 
max degree heuristic while the value heuristic is a custom heuristic that selects the most available worker for a position.

\subsubsection{Variable Heuristic}

The variable heuristic used for the search is a custom max degree heuristic. 
The degree of a variable is the number of constraints assigned to it. However, as skills are not stated with constraints, 
we add the number of required skills for a position to the degree. 
We also make sure that if a variable is of size two, it is always selected first to avoid having the dummy value $\sigma$ assigned to it by 
propagation.


\subsubsection{Most Available Value Heuristic}

We define a value heuristic that we call the \emph{most available heuristic}. 
This heuristic consists of two value orderings.
\begin{enumerate}
  \item The first ordering orders the workers from most available to least available throughout the duration of the demand.
        This allows the search to select workers that are more likely to work for that demand throughout all periods.
  \item If workers have the same availabilities for a demand, they are ordered with respect to their remaining availabilities in other demands. This 
        second ordering is important for smaller demands, the search chooses workers that are less likely to be needed in other demands.
\end{enumerate}

It also never considers the dummy worker $\sigma$ for the worker value as it is not even considered 
for the most available worker. This value heuristic will in practice find solutions much quicker than a traditional \emph{min} value heuristic 
(see \autoref{section:experiments:heuristics}).

Let us take an example to show how this heuristic works in practice, let us define 
$w_1$, $w_2$ and $w_3$, three possible workers for two demands $d_1$ and $d_2$ that only need one worker each.
The availabilities are defined as
$w_1^T = \{ 0, 1, 2 \}$, $w_2^T = \{ 0, 2 \}$, $w_3^T = \{ 0, 1, 2, 3, 4\}$ and the demand occurrences as 
$d_1^T = \{ 0, 1, 2 \}$, $d_2^T = \{ 0, 1, 2, 3, 4 \}$. Intuitively, we can see that worker 
$w_3$ should be assigned to $d_2$ and $w_1$ should be assigned to $d_1$. This is what the heuristic tries to achieve, the ordering for each demand is as follows:

\begin{align*}
  \texttt{mostavailable}(d_1) &= [w_1 = (3, 0), w_3 = (3, 2), w_2 = (2, 0)] \\ 
  \texttt{mostavailable}(d_2) &= [w_3 = (5, 0), w_3 = (3, 0), w_2 = (2, 0)] \\ 
\end{align*}

First, we can see that $w_2$ is never considered in this case as it is not available enough. For $d_1$, both $w_1$ and $w_3$ have the 3 availabilities. However, 
$w_3$ has two remaining availabilities. This heuristic guesses that those two remaining availabilities could be used elsewhere. In this case, it is used on $d_2$ where $w_3$ has all his 5 availabilities.
The search always considers $w_1$ first for $d_1$ and $w_3$ first for $d_2$.

\subsubsection{Dynamic Value Heuristic}

The \emph{most available} heuristic works fairly well in practice as seen in \autoref{chapter:experiments}. 
We can, however, improve it by making it more dynamic to the search. Instead of one static ordering at the start of the search,
we can reorder values at each value selection to select the best worker in the current search tree.

To achieve this, we need to store some state during the search that will backtrack automatically.

\begin{enumerate}
  \item $occ_{wdp}$: the number of times worker $w$ already works for position $p$ of demand $d$.
  \item $occ_{w}$: the number of times worker $w$ already works in any demands.
  \item $a_{w} \subseteq w^T$: the set of remaining availabilities of the worker $w$.
\end{enumerate}

We now have three levels of ordering in the heuristic:

\begin{enumerate}
  \item The first ordering is now the occurrences $occ_{wpd}$ from greatest to smallest values. We prioritize workers that already work for this demand for the longest time.
  \item The second ordering is the same as the first static ordering except we now take into account the 
        remaining availabilities of the worker $a_w$ to select the most available worker.
  \item The third ordering is the second static ordering except we also take into account the number of times the worker 
        is already assigned $occ_w$.
\end{enumerate}


\subsubsection{Working requirements extension}

One pitfall with our aforementioned heuristic is that a worker might have working requirements 
but not enough availabilities for this worker to be selected by the search. We can slightly improve our most available heuristic by adding a small extension to take into account
the working requirements. This extension adds two orderings in front of all other orderings:


\begin{enumerate}
  \item If $r_{max}$ is equal to $occ_{w}$ for worker $w$, we consider this worker last.
  \item $\text{max}(r_{min} - occ_{w}, 0)$ orders the workers by their remaining requirements. We 
  take the workers that have the most requirements first.
  $r_{min}$ is the minimum requirement for worker $w$. We take the subtraction of this value with the current 
  occurrences of worker $w$ and we max this result with 0 to avoid having negative values which are not relevant in our case.
\end{enumerate}

For the remaining of this thesis, when we talk about the most available heuristic, we also take into account this extension.

\subsubsection{Breaking symmetries}

It is fairly easy to see that our problem contains a lot of symmetries between different positions within the same demand. 
Two positions might require no skill and thus have the same possible workers. We want to avoid as much as possible to consider every permutation of those workers.
For this, we use the \texttt{lexleq} constraint \cite{Alan:Lex}. This constraint takes two vectors of variables $X$ and $Y$. It ensures that 
$x_i \leq y_i \ \forall i$. As we already have an \texttt{alldifferent} constraint applied, it ensures $x_i < y_i \ \forall i$.
Let $x_i \in X$ be a variable symmetric to $y_i \in Y$ where $x_i$ and $y_i$ are two variables from the same demand occurring at the same time period.


\begin{equation}
  \texttt{lexleq}(X, Y)
\end{equation}

As a simple example, let us define $x_1 = x_2 = \{ 1, 2, 3 \}$ with $x_1 < x_2$ for symmetry breaking. If 
$x_1$ is assigned the value $2$, we ignore the permutation $x_1 = 2, x_2 = 1$ because it is symmetric to $x_1 = 1, x_2 = 2$. $x_2$ is instead directly assigned to the value $3$ and thus reducing the search space.
\autoref{tree:symmetry} shows the search trees with and without symmetry breaking. We can see that the search tree with the \texttt{lexleq} constraint is reduced.

\forestset{qtree/.style={for tree={draw, parent anchor=south, 
           rounded corners,
           align=center, l sep=40pt, s sep=20pt}}}

\begin{figure}
  \begin{adjustbox}{valign=t, center}
  \begin{forest}, baseline, qtree
    % for tree={l sep=20pt}
    [{\footnotesize$x = \{1, 2, 3\}$\\\footnotesize$y = \{ 1, 2, 3 \}$}
      [{\footnotesize$x = 1$\\\footnotesize$y = \{ 2, 3 \}$}, edge label={node[midway,left] {$x=1$}} 
      [{\footnotesize$x = 1$\\\footnotesize$y = 2$}, edge label={node[midway,left] {$y=2$}} ]
      [{\footnotesize$x = 1$\\\footnotesize$y = 3$}, edge label={node[midway,right] {$y=3$}} ]
      ]
      [{\footnotesize$x = 2$\\\footnotesize$y = 3$}, edge label={node[midway,right] {$x\neq1$}} ]
    ]
  \end{forest}
  
  \begin{forest}, baseline, qtree
    % for tree={l sep=20pt}
    [{\footnotesize$x = \{1, 2, 3\}$\\\footnotesize$y = \{ 1, 2, 3 \}$}
      [{\footnotesize$x = \{1\}$\\\footnotesize$y = \{ 2, 3 \}$}, edge label={node[midway,left] {$x=1$}} 
        [{\footnotesize$x = 1$\\\footnotesize$y = 2$}, draw={blue}, edge label={node[midway,left] {$y=2$}} ]
        [{\footnotesize$x = 1$\\\footnotesize$y = 3$}, draw={red}, edge label={node[midway,right] {$y=3$}} ]
      ]
      [{\footnotesize$x = \{ 2, 3 \}$\\\footnotesize$y = \{ 1, 2, 3 \}$}, edge label={node[midway,right] {$x\neq1$}} 
        [{\footnotesize$x = 2$\\\footnotesize$y = \{ 1, 3 \}$}, edge label={node[midway,left] {$x = 2$}} 
          [{\footnotesize$x = 2$\\\footnotesize$y = 1$}, draw={blue}, edge label={node[midway,left] {$y=1$}} ]
          [{\footnotesize$x = 2$\\\footnotesize$y = 3$}, draw={green}, edge label={node[midway,right] {$y=3$}} ]
        ]
        [{\footnotesize$x = 3$\\\footnotesize$y = \{ 1, 2 \}$}, edge label={node[midway,right] {$x = 3$}} 
          [{\footnotesize$x = 3$\\\footnotesize$y = 1$}, draw={red}, edge label={node[midway,left] {$y=1$}} ]
          [{\footnotesize$x = 3$\\\footnotesize$y = 2$}, draw={green}, edge label={node[midway,right] {$y=2$}} ]
        ]  
      ]
    ]
  \end{forest}
  \end{adjustbox}
  \caption{Search tree with symmetry breaking (left) and without (right)}
  \label{tree:symmetry}
\end{figure}

\subsubsection{Large Neighborhood Search}

We use LNS to ensure that we explore as much of the search space as possible. 
We used both Random Relaxation and Propagation Guided Relaxation \cite{Propagation:LNS} to relax 
our best solution. We discuss and compare these relaxations in \autoref{chapter:experiments}.


\subsubsection{Variable Objective LNS}
\label{cp:volns}

Our problem uses a multi-objective (\ref{cp:objective}) model. 
Let us define $o_1 = \text{min} \ v_{\sigma}$, $o_2 = {\text{min} \ v_r}$, $o_3 = {\text{min} \ \sum_{j \in D} \sum_{k \in D^P_j} N_{jk}}$
and $o_4$ is the original weighted sum described in (\ref{cp:objective}).


We wish to optimize sub-objectives $o_1$ and $o_2$ first to avoid partial solutions and unmet requirements respectively. 

\begin{enumerate}
  \item First set $o_1$ to \emph{Strong-Filtering} while others are set to \emph{No-Filtering}.
  \item Once optimized or if it met a threshold, set $o_2$ to \emph{Strong-Filtering}, $o_1$ to \emph{Weak-Filtering} and others to \emph{No-Filtering}.
  \item Once $o_2$ is optimized or met a threshold, keep it in \emph{Weak-Filtering} for the rest of the search and switch $o_3$ to \emph{Strong-Filtering}.
\end{enumerate}

$o_4$ is also kept in \emph{Strong-Filtering} mode for the entire duration of the search to avoid having a weaker model than the original weighted sum.

\end{document}

