% !TEX root = ../thesis.tex

\documentclass[../thesis.tex]{subfiles}
 
\begin{document}

In this chapter, we describe our implementation for the models presented in \autoref{chapter:models}. 
We talk about the difficulties encountered while trying to transform the theoretical model to code. 
We will also discuss some differences between the models and the implementation and some trade-offs that were taken in order to 
have the most performant solver.

The implementation was done in Scala using 
\emph{OscaR} (\ref{subsection:oscar}) as CP solver and
\emph{Gurobi Optimizer} (\ref{subsection:gurobi}) as MIP solver. The general implementation 
tries to keep the same API (Application Programming Interface) for the CP and MIP solvers with the only changes being optional options 
that can be passed to it. 



\section{Input and output format}

For consistency, both solvers take the same input format and return the same output format.
We created a JSON (JavaScript Object Notation) Schema \cite{json:schema} to formulate our problems and solution assignments.
Those schemas allow us to create a typed data structure for JSON objects. All the typing validation 
is handled by the JSON Schema library. A small example of JSON schema can be found in \autoref{json:example}. 
This example defines a client structure which takes a required string property called \textit{name}.


\begin{lstlisting}[language=json,firstnumber=1,caption={JSON Schema example},captionpos=b,label={json:example}]
  "client": {
    "type": "object",
    "properties": {
      "name": {
        "type": "string"
      }
    },
    "required": ["name"]
  }
\end{lstlisting}

The data is parsed into an immutable data structure in Scala which looks like this:

\begin{lstlisting}[style=scalaStyle,caption={Problem structure in Scala},captionpos=b]
case class Problem(
  T: Int,
  demands: Array[Demand],
  workers: Array[Worker],
  clients: Array[Client],
  locations: Array[Location] = Array(),
  machines: Array[Machine] = Array(),
  workerWorkerIncompatibilities: Array[Array[Int]] = Array(),
  workerClientIncompatibilities: Array[Array[Int]] = Array(),
  workingRequirements: Array[WorkingRequirement] = Array(),
  initialSolution: Option[Solution] = None
)
\end{lstlisting}


\section{Common solver API}

Both solvers implement a \texttt{solve} function which takes the same set of parameters.
This function can take generic options implemented by the subclasses (i.e. specific MIP or CP options).

\begin{lstlisting}[style=scalaStyle,caption={Solver API},captionpos=b]
trait SearchOptions

trait Search[T <: SearchOptions] {
  def solve(timeLimit: Int, solutionLimit: Int, silent: Boolean, options: Option[T] = None): SearchResult
}
\end{lstlisting}

\section{Mixed Integer Programming solver}

We used the Java API \cite{gurobi:java} of the Gurobi Optimizer in Scala to create our implementation. 
The implementation did not change from the theoretical model presented in \autoref{section:mipmodel} as 
MIP solvers are less flexible in their modeling abilities than CP solvers as we discuss later. The Gurobi solver 
comes with default parameters \cite{gurobi:parameters}, it is advised to keep default parameters as 
changing them do not give much gain. Multiple different parameters were tested but as advised from the Gurobi website, 
no change was noticed.

\section{Constraint Programming solver}

The Constraint Programming implementation differs in some parts from the theoretical model 
presented in \autoref{section:cpmodel}. In Constraint Programming, the constraint propagation 
takes the most time in the solving algorithm. Propagations might be unnecessary too strong for a model.
This is what happened with our model and the use of \texttt{softgcc} constraints. 

The minimization of fictitious workers described in (\ref{cp:fictitious}) used a \texttt{softgcc} in the model.
However, this constraint is slow to propagate in practice due to the high number of variables.
Using a CPU profiler, we noticed the \texttt{softgcc} constraint took up to 20\% of the solver runtime. 
OscaR proposes a variant of the \texttt{gcc} constraint which simply count the number of occurrences of values.


\begin{lstlisting}[style=scalaStyle,label={gcc_oscar},caption={Variant of \texttt{gcc} implemented in OscaR},captionpos=b]
gcc(x: Array[CPIntVar], o: Array[(Int, CPIntVar)])
\end{lstlisting}

This definition offers a weaker propagation for the variables but is enough for our model. 
This definition is used as follows:


\begin{lstlisting}[style=scalaStyle,label={gcc_oscar_2},caption={Usage of \texttt{gcc} to count fictitious workers},captionpos=b]
  // workerVariables: Array[CPIntVar]
  // sentinelViolations: CPIntVar
  // Constants.SentinelWorker: Int = -1
  add(
    gcc(workerVariables, Array(
        (Constants.SentinelWorker, sentinelViolations)
      )
    )
  )
\end{lstlisting}

We followed the same idea for the working requirements minimization (\ref{cp:wrequirements}). \texttt{softgcc} also turned out to be too strong.
We used a weaker model with the \texttt{gcc} described above and computed our own violations, similar to the \texttt{softgcc} definition,
from the occurrences given by the \texttt{gcc}.


\begin{lstlisting}[style=scalaStyle,label={gcc_oscar_2},caption={Usage of \texttt{gcc} to count working requirements violations},captionpos=b]
case class WorkingRequirement(worker: Int, min: Option[Int], max: Option[Int])

// ...

val violations: Array[CPIntVar] = Array.fill(requirements.length)(null)

val occurrences = requirements
  .map(_.worker)
  .map(w => (w, CPIntVar(0, workers(w).availabilities.size)))

add(gcc(workerVariables, occurrences))

// For each requirement 
for (i <- requirements.indices) {
  val r = requirements(i)
  violations(i) = maximum(Array(
      occurrences(i)._2 - r.max.getOrElse(workers(r.worker).availabilities.size),
      -occurrences(i)._2 + r.min.getOrElse(0),
      CPIntVar(Set(0))
    )
  )
}

// workingRequirementsViolations: CPIntVar
add(sum(violations, workingRequirementsViolations))
\end{lstlisting}


\section{Instances generation}
\label{section:instance-gen}

Randomized instances were needed to be able to test our solvers. Unfortunately, we were not 
able to have real testing data to base our generation on. 

A generator was implemented with a series of options to create different types of instances. The options are the following:


\begin{lstlisting}[style=scalaStyle,label={instance:options},caption={Instance options},captionpos=b]
case class InstanceOptions(
  t: Int,                                   // Number of periods 
  clients: Int,                             // Number of clients 
  demands: Int,                             // Number of demands 
  workers: Int,                             // Number of workers 
  skills: Int,                              // Number of skills 
  locations: Int = 0,                       // Number of locations 
  machines: Int = 0,                        // Number of machines
  probabilities: Map[String, Double] = Map(
    "assignSkill" -> 0.2,                   // Assign skill to demand
    "assignWorkerSkill" -> 0.2,             // Assign skill to worker
    "assignPeriod" -> 0.6,                  // Assign period to demand
    "assignLocation" -> 0.5,                // Assign location to demand
    "assignMachines" -> 0.3,                // Assign machines to demand
    "takeMachine" -> 0.2,                   // Assign a machine to demand
    "assignWorkingRequirements" -> 0.2,     // Assign requirements to worker
    "assignWWI" -> 0.05,                    // Assign worker-worker 
                                            // incompatibility for each worker 
    "assignWCI" -> 0.05                     // Assign worker-client
                                            // incompatibility for each worker
  )
)
\end{lstlisting}

This represent almost all the parameters that an instance can have. We created a
map of probabilities to generate easier or harder instances. For example,
the \texttt{assignSkill} value is responsible for the probability of a position to be assigned a skill. 
We can increase this value if we want more skilled positions and vice-versa.

We also needed to be able to reproduce instances, the \texttt{InstanceGenerator} API can 
take a seed which defaults at $0$.

  
\begin{lstlisting}[style=scalaStyle,caption={Instance generator API},captionpos=b]
class InstanceGenerator(val seed: Long = 0L) {
  def generate(options: InstanceOptions): Problem
}
\end{lstlisting}

The generator makes sure that a solution is always possible by assigning periods to workers 
that have been assigned to demands. It also adds the demand periods to $k$ random workers
where $k$ is the number of required workers for that demand. This allows having more solutions variety.
    
The generator tries as much as possible to create meaningful instances but it is of course not able to replicate the importance of real data properly.

\section{Benchmark runner}
\label{section:benchmark-runner}

A benchmark API is created on top of the instances generation API. The API takes an options structure (\autoref{benchmark:options}).
The arrays \texttt{T}, \texttt{D} and \texttt{W} determine the sizes of the instances. The benchmark runner 
will create instances with a combination of those parameters. For example, with the values in \autoref{benchmark:options},
the benchmark runner will create 6 instances with the sizes: $(5, 30, 100)$, $(5, 50, 100)$, $(5, 30, 200)$, $(5, 50, 200)$, $(5, 30, 300)$ and $(5, 50, 300)$ with the 
three values being $(T, D, W)$.

\begin{lstlisting}[style=scalaStyle,label={benchmark:options},caption={Benchmark options},captionpos=b]
trait BenchmarkOptions {
  val solutionLimit: Int = Int.MaxValue
  val timeLimit: Int = 20
  val repeat: Int = 1
  val dryRun: Int = 1
  val T: Array[Int] = Array(5)
  val D: Array[Int] = Array(30, 50)
  val W: Array[Int] = Array(100, 200, 300)
  val probabilities: Map[String, Double] = Map()
  val seed: Long = -1L
}
\end{lstlisting}

We can specify a solution limit as well as a time limit. We can also repeat our benchmark and takes 
the average of results. We can also have dry runs to warm up the JVM (Java Virtual Machine) and a seed to have reproducible benchmarks. Finally,
we can specify the probabilities for our instances as explained in \autoref{section:instance-gen}.

Our benchmark runner has a function \texttt{run} that takes a name (e.g. solver name, serie name, etc), and a solving function 
which takes a generic model and returns a pair with the time spent in milliseconds and the objective value respectively.

\begin{lstlisting}[style=scalaStyle,label={benchmark:run},caption={Benchmark run function},captionpos=b]
class BenchmarkRunner(val options: BenchmarkOptions) {
  def run (
    name: String, 
    solve: VillageOneModel => (Long, Int)
  ): (BenchmarkSerie, BenchmarkSerie)
}
\end{lstlisting}

This function returns a pair of benchmark series: one serie for the time values and one serie for the objective values.
The \texttt{BenchmarkSerie} class is simply a class that takes a name and a list of benchmark measurements (i.e. mean, standard deviation, min and max).

This implementation allows us to create a variety of benchmark by simply changing the \texttt{solve} function.


\end{document}

